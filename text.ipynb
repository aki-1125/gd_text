{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deadly-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recorded-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"20210413_GD_theme5_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relative-packaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposed-carol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>utterance time</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:28:00</td>\n",
       "      <td>10:28:40</td>\n",
       "      <td>0:00:40</td>\n",
       "      <td>林</td>\n",
       "      <td>大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:28:52</td>\n",
       "      <td>10:29:16</td>\n",
       "      <td>0:00:24</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>自分も大学教育はそれだけの価値があると思います．大学で教育を受けることで就活において有利に働...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:29:18</td>\n",
       "      <td>10:30:47</td>\n",
       "      <td>0:01:29</td>\n",
       "      <td>勝澤</td>\n",
       "      <td>自分は大学教育に価値があるかといいますと，えーうーんその価値を自分で見出せるかていうところが...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:29:52</td>\n",
       "      <td>10:30:59</td>\n",
       "      <td>0:01:07</td>\n",
       "      <td>小杉</td>\n",
       "      <td>自分は大学教育に価値があるかという話だと思うんですけれども，そこまで価値を見出すことはできな...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:31:08</td>\n",
       "      <td>10:31:12</td>\n",
       "      <td>0:00:04</td>\n",
       "      <td>林</td>\n",
       "      <td>え，勝澤君．いいっすよさっきの理由を言って</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:31:44</td>\n",
       "      <td>10:32:36</td>\n",
       "      <td>0:00:52</td>\n",
       "      <td>勝澤</td>\n",
       "      <td>えーと，でもどりますと，大学に行っていない自分の友人がいるんですけど，それでも普通にえーと，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:32:42</td>\n",
       "      <td>10:33:22</td>\n",
       "      <td>0:00:40</td>\n",
       "      <td>林</td>\n",
       "      <td>確かになー自分の学びたいことがないと別に価値があるか確かにな，まあ正直，なんていうんでしょう...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:33:25</td>\n",
       "      <td>10:34:09</td>\n",
       "      <td>0:00:44</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>自分は大学教育がいらないっていうその道が決まってて，その方針があってその専門学校に向かうのか...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:34:10</td>\n",
       "      <td>10:34:56</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>小杉</td>\n",
       "      <td>ひとつ，その意見で思ったのは，ある一定レベル以上の大学っていうのはまあ，それぞれの学問に対し...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:34:59</td>\n",
       "      <td>10:35:33</td>\n",
       "      <td>0:00:34</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>それに関しては，その人そこに入る大学生っていうのは，高校の分野もろくに学べてない人たちであっ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:35:40</td>\n",
       "      <td>10:36:21</td>\n",
       "      <td>0:00:41</td>\n",
       "      <td>林</td>\n",
       "      <td>うーんと，さっき宍戸君が言っていたなんか，広く浅くみたいな高校のときはまだ決められてないから...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:36:22</td>\n",
       "      <td>10:36:52</td>\n",
       "      <td>0:00:30</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>どこの学部もそうだけど，ジャンルが確かに狭まっちゃうかなと思うけど，英語だったり、数学だった...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:37:31</td>\n",
       "      <td>10:38:03</td>\n",
       "      <td>0:00:32</td>\n",
       "      <td>林</td>\n",
       "      <td>価値，価値かー．でもそれにしても，大学のお金って高いですよね，なんでそんな高いんでしょうね．...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:38:04</td>\n",
       "      <td>10:38:23</td>\n",
       "      <td>0:00:19</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>まあ，一応あれですね．大学の言い分的には施設維持費とかで後生に残すために，お金をとっている部...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:38:29</td>\n",
       "      <td>10:38:50</td>\n",
       "      <td>0:00:21</td>\n",
       "      <td>小杉</td>\n",
       "      <td>根本的に学生が3年までに取り終えるようにとっているから4年って授業がないだけで，本来の大学と...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:38:52</td>\n",
       "      <td>10:39:16</td>\n",
       "      <td>0:00:24</td>\n",
       "      <td>林</td>\n",
       "      <td>え，でもその逆に，その4年間の中で，お金を大量に支払ってきてそれくらいの価値はありましたか．...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:39:17</td>\n",
       "      <td>10:39:35</td>\n",
       "      <td>0:00:18</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>一般的に，大卒の人の方が，生涯年金や生涯収入がどんどん上がっていくからそれを考えた投資ってい...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:39:37</td>\n",
       "      <td>10:39:52</td>\n",
       "      <td>0:00:15</td>\n",
       "      <td>小杉</td>\n",
       "      <td>入学してきたっていうことは，そこに価値を見出したから入ってきたっていうのはあるかもしれない．...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:39:59</td>\n",
       "      <td>10:40:01</td>\n",
       "      <td>0:00:02</td>\n",
       "      <td>林</td>\n",
       "      <td>確かにな，価値な．</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:40:05</td>\n",
       "      <td>10:40:55</td>\n",
       "      <td>0:00:50</td>\n",
       "      <td>小杉</td>\n",
       "      <td>でも，現状としてはやっぱりなんとなく入るって言う人がとても多いと思うので，うーん，まあ，大学...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021/4/13</td>\n",
       "      <td>10:41:12</td>\n",
       "      <td>10:41:32</td>\n",
       "      <td>0:00:20</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>まあ，なんとなく通っていても，大学のネームバリューがあるから，それなりの企業には行けてしまう...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021/4/14</td>\n",
       "      <td>10:41:36</td>\n",
       "      <td>10:41:39</td>\n",
       "      <td>0:00:03</td>\n",
       "      <td>林</td>\n",
       "      <td>でも，結構そしたら無名の大学に行く意味はなくなっちゃうじゃないですか．</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021/4/15</td>\n",
       "      <td>10:41:40</td>\n",
       "      <td>10:41:57</td>\n",
       "      <td>0:00:17</td>\n",
       "      <td>宍戸</td>\n",
       "      <td>そーすね．無名の大学．まあ，それでも大卒っていう職歴って書けるからそこはいいんじゃないんです...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021/4/16</td>\n",
       "      <td>10:42:17</td>\n",
       "      <td>10:42:22</td>\n",
       "      <td>0:00:05</td>\n",
       "      <td>小杉</td>\n",
       "      <td>林君は価値があると思うんですか，ないと思うんですかね．</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021/4/17</td>\n",
       "      <td>10:42:23</td>\n",
       "      <td>10:43:15</td>\n",
       "      <td>0:00:52</td>\n",
       "      <td>林</td>\n",
       "      <td>自分は，最初価値はあるって思っていたんですけど，なんかやっぱり話しているうちに価値がないのか...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date start_time finish_time utterance time speaker  \\\n",
       "0   2021/4/13   10:28:00    10:28:40        0:00:40      林    \n",
       "1   2021/4/13   10:28:52    10:29:16        0:00:24      宍戸   \n",
       "2   2021/4/13   10:29:18    10:30:47        0:01:29      勝澤   \n",
       "3   2021/4/13   10:29:52    10:30:59        0:01:07      小杉   \n",
       "4   2021/4/13   10:31:08    10:31:12        0:00:04      林    \n",
       "5   2021/4/13   10:31:44    10:32:36        0:00:52      勝澤   \n",
       "6   2021/4/13   10:32:42    10:33:22        0:00:40      林    \n",
       "7   2021/4/13   10:33:25    10:34:09        0:00:44      宍戸   \n",
       "8   2021/4/13   10:34:10    10:34:56        0:00:46      小杉   \n",
       "9   2021/4/13   10:34:59    10:35:33        0:00:34      宍戸   \n",
       "10  2021/4/13   10:35:40    10:36:21        0:00:41      林    \n",
       "11  2021/4/13   10:36:22    10:36:52        0:00:30      宍戸   \n",
       "12  2021/4/13   10:37:31    10:38:03        0:00:32      林    \n",
       "13  2021/4/13   10:38:04    10:38:23        0:00:19      宍戸   \n",
       "14  2021/4/13   10:38:29    10:38:50        0:00:21      小杉   \n",
       "15  2021/4/13   10:38:52    10:39:16        0:00:24      林    \n",
       "16  2021/4/13   10:39:17    10:39:35        0:00:18      宍戸   \n",
       "17  2021/4/13   10:39:37    10:39:52        0:00:15      小杉   \n",
       "18  2021/4/13   10:39:59    10:40:01        0:00:02      林    \n",
       "19  2021/4/13   10:40:05    10:40:55        0:00:50      小杉   \n",
       "20  2021/4/13   10:41:12    10:41:32        0:00:20      宍戸   \n",
       "21  2021/4/14   10:41:36    10:41:39        0:00:03       林   \n",
       "22  2021/4/15   10:41:40    10:41:57        0:00:17      宍戸   \n",
       "23  2021/4/16   10:42:17    10:42:22        0:00:05      小杉   \n",
       "24  2021/4/17   10:42:23    10:43:15        0:00:52       林   \n",
       "\n",
       "                                                 text  \n",
       "0   大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に...  \n",
       "1   自分も大学教育はそれだけの価値があると思います．大学で教育を受けることで就活において有利に働...  \n",
       "2   自分は大学教育に価値があるかといいますと，えーうーんその価値を自分で見出せるかていうところが...  \n",
       "3   自分は大学教育に価値があるかという話だと思うんですけれども，そこまで価値を見出すことはできな...  \n",
       "4                               え，勝澤君．いいっすよさっきの理由を言って  \n",
       "5   えーと，でもどりますと，大学に行っていない自分の友人がいるんですけど，それでも普通にえーと，...  \n",
       "6   確かになー自分の学びたいことがないと別に価値があるか確かにな，まあ正直，なんていうんでしょう...  \n",
       "7   自分は大学教育がいらないっていうその道が決まってて，その方針があってその専門学校に向かうのか...  \n",
       "8   ひとつ，その意見で思ったのは，ある一定レベル以上の大学っていうのはまあ，それぞれの学問に対し...  \n",
       "9   それに関しては，その人そこに入る大学生っていうのは，高校の分野もろくに学べてない人たちであっ...  \n",
       "10  うーんと，さっき宍戸君が言っていたなんか，広く浅くみたいな高校のときはまだ決められてないから...  \n",
       "11  どこの学部もそうだけど，ジャンルが確かに狭まっちゃうかなと思うけど，英語だったり、数学だった...  \n",
       "12  価値，価値かー．でもそれにしても，大学のお金って高いですよね，なんでそんな高いんでしょうね．...  \n",
       "13  まあ，一応あれですね．大学の言い分的には施設維持費とかで後生に残すために，お金をとっている部...  \n",
       "14  根本的に学生が3年までに取り終えるようにとっているから4年って授業がないだけで，本来の大学と...  \n",
       "15  え，でもその逆に，その4年間の中で，お金を大量に支払ってきてそれくらいの価値はありましたか．...  \n",
       "16  一般的に，大卒の人の方が，生涯年金や生涯収入がどんどん上がっていくからそれを考えた投資ってい...  \n",
       "17  入学してきたっていうことは，そこに価値を見出したから入ってきたっていうのはあるかもしれない．...  \n",
       "18                                          確かにな，価値な．  \n",
       "19  でも，現状としてはやっぱりなんとなく入るって言う人がとても多いと思うので，うーん，まあ，大学...  \n",
       "20  まあ，なんとなく通っていても，大学のネームバリューがあるから，それなりの企業には行けてしまう...  \n",
       "21                でも，結構そしたら無名の大学に行く意味はなくなっちゃうじゃないですか．  \n",
       "22  そーすね．無名の大学．まあ，それでも大卒っていう職歴って書けるからそこはいいんじゃないんです...  \n",
       "23                        林君は価値があると思うんですか，ないと思うんですかね．  \n",
       "24  自分は，最初価値はあるって思っていたんですけど，なんかやっぱり話しているうちに価値がないのか...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faced-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に...\n",
       "1     自分も大学教育はそれだけの価値があると思います．大学で教育を受けることで就活において有利に働...\n",
       "2     自分は大学教育に価値があるかといいますと，えーうーんその価値を自分で見出せるかていうところが...\n",
       "3     自分は大学教育に価値があるかという話だと思うんですけれども，そこまで価値を見出すことはできな...\n",
       "4                                 え，勝澤君．いいっすよさっきの理由を言って\n",
       "5     えーと，でもどりますと，大学に行っていない自分の友人がいるんですけど，それでも普通にえーと，...\n",
       "6     確かになー自分の学びたいことがないと別に価値があるか確かにな，まあ正直，なんていうんでしょう...\n",
       "7     自分は大学教育がいらないっていうその道が決まってて，その方針があってその専門学校に向かうのか...\n",
       "8     ひとつ，その意見で思ったのは，ある一定レベル以上の大学っていうのはまあ，それぞれの学問に対し...\n",
       "9     それに関しては，その人そこに入る大学生っていうのは，高校の分野もろくに学べてない人たちであっ...\n",
       "10    うーんと，さっき宍戸君が言っていたなんか，広く浅くみたいな高校のときはまだ決められてないから...\n",
       "11    どこの学部もそうだけど，ジャンルが確かに狭まっちゃうかなと思うけど，英語だったり、数学だった...\n",
       "12    価値，価値かー．でもそれにしても，大学のお金って高いですよね，なんでそんな高いんでしょうね．...\n",
       "13    まあ，一応あれですね．大学の言い分的には施設維持費とかで後生に残すために，お金をとっている部...\n",
       "14    根本的に学生が3年までに取り終えるようにとっているから4年って授業がないだけで，本来の大学と...\n",
       "15    え，でもその逆に，その4年間の中で，お金を大量に支払ってきてそれくらいの価値はありましたか．...\n",
       "16    一般的に，大卒の人の方が，生涯年金や生涯収入がどんどん上がっていくからそれを考えた投資ってい...\n",
       "17    入学してきたっていうことは，そこに価値を見出したから入ってきたっていうのはあるかもしれない．...\n",
       "18                                            確かにな，価値な．\n",
       "19    でも，現状としてはやっぱりなんとなく入るって言う人がとても多いと思うので，うーん，まあ，大学...\n",
       "20    まあ，なんとなく通っていても，大学のネームバリューがあるから，それなりの企業には行けてしまう...\n",
       "21                  でも，結構そしたら無名の大学に行く意味はなくなっちゃうじゃないですか．\n",
       "22    そーすね．無名の大学．まあ，それでも大卒っていう職歴って書けるからそこはいいんじゃないんです...\n",
       "23                          林君は価値があると思うんですか，ないと思うんですかね．\n",
       "24    自分は，最初価値はあるって思っていたんですけど，なんかやっぱり話しているうちに価値がないのか...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "representative-occupation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に価値があると思います．結構高校では教わらない専門的な知識も教えてもらえたりするし，まあ，もっと分野に対して詳しく説明されたりするから価値があると思います．'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "directed-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "tokenizer = MeCab.Tagger(\"-Ochasen\")\n",
    "text_mecab = []\n",
    "for i in range(0, len(text)):\n",
    "    a = tokenizer.parse(text[\"text\"][i])\n",
    "    text_mecab.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "infectious-chamber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自分\tジブン\t自分\t名詞-一般\t\t\n",
      "も\tモ\tも\t助詞-係助詞\t\t\n",
      "大学\tダイガク\t大学\t名詞-一般\t\t\n",
      "教育\tキョウイク\t教育\t名詞-サ変接続\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "それだけ\tソレダケ\tそれだけ\t副詞-助詞類接続\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "価値\tカチ\t価値\t名詞-一般\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "ある\tアル\tある\t動詞-自立\t五段・ラ行\t基本形\n",
      "と\tト\tと\t助詞-格助詞-引用\t\t\n",
      "思い\tオモイ\t思う\t動詞-自立\t五段・ワ行促音便\t連用形\n",
      "ます\tマス\tます\t助動詞\t特殊・マス\t基本形\n",
      "．\t．\t．\t記号-句点\t\t\n",
      "大学\tダイガク\t大学\t名詞-一般\t\t\n",
      "で\tデ\tで\t助詞-格助詞-一般\t\t\n",
      "教育\tキョウイク\t教育\t名詞-サ変接続\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "受ける\tウケル\t受ける\t動詞-自立\t一段\t基本形\n",
      "こと\tコト\tこと\t名詞-非自立-一般\t\t\n",
      "で\tデ\tで\t助詞-格助詞-一般\t\t\n",
      "就活\t就活\t就活\t名詞-一般\t\t\n",
      "において\tニオイテ\tにおいて\t助詞-格助詞-連語\t\t\n",
      "有利\tユウリ\t有利\t名詞-形容動詞語幹\t\t\n",
      "に\tニ\tに\t助詞-副詞化\t\t\n",
      "働く\tハタラク\t働く\t動詞-自立\t五段・カ行イ音便\t基本形\n",
      "こと\tコト\tこと\t名詞-非自立-一般\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "周知\tシュウチ\t周知\t名詞-サ変接続\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "事実\tジジツ\t事実\t名詞-副詞可能\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "し\tシ\tし\t助詞-接続助詞\t\t\n",
      "，\t，\t，\t記号-読点\t\t\n",
      "その\tソノ\tその\t連体詞\t\t\n",
      "社会\tシャカイ\t社会\t名詞-一般\t\t\n",
      "人\tジン\t人\t名詞-接尾-一般\t\t\n",
      "に\tニ\tに\t助詞-格助詞-一般\t\t\n",
      "なる\tナル\tなる\t動詞-自立\t五段・ラ行\t基本形\n",
      "前\tマエ\t前\t名詞-副詞可能\t\t\n",
      "の\tノ\tの\t助詞-連体化\t\t\n",
      "準備\tジュンビ\t準備\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "できる\tデキル\tできる\t動詞-自立\t一段\t基本形\n",
      "と\tト\tと\t助詞-格助詞-引用\t\t\n",
      "思い\tオモイ\t思う\t動詞-自立\t五段・ワ行促音便\t連用形\n",
      "ます\tマス\tます\t助動詞\t特殊・マス\t基本形\n",
      "．\t．\t．\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_mecab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "noticed-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "meisi = []\n",
    "for i in range(0, len(text)):\n",
    "    if \"名詞\" in text_mecab[i].split()[-1]:\n",
    "        meisi.append(\"名詞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "written-feelings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "rapid-shopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'自分\\tジブン\\t自分\\t名詞-一般\\t\\t\\nも\\tモ\\tも\\t助詞-係助詞\\t\\t\\n大学\\tダイガク\\t大学\\t名詞-一般\\t\\t\\n教育\\tキョウイク\\t教育\\t名詞-サ変接続\\t\\t\\nは\\tハ\\tは\\t助詞-係助詞\\t\\t\\nそれだけ\\tソレダケ\\tそれだけ\\t副詞-助詞類接続\\t\\t\\nの\\tノ\\tの\\t助詞-連体化\\t\\t\\n価値\\tカチ\\t価値\\t名詞-一般\\t\\t\\nが\\tガ\\tが\\t助詞-格助詞-一般\\t\\t\\nある\\tアル\\tある\\t動詞-自立\\t五段・ラ行\\t基本形\\nと\\tト\\tと\\t助詞-格助詞-引用\\t\\t\\n思い\\tオモイ\\t思う\\t動詞-自立\\t五段・ワ行促音便\\t連用形\\nます\\tマス\\tます\\t助動詞\\t特殊・マス\\t基本形\\n．\\t．\\t．\\t記号-句点\\t\\t\\n大学\\tダイガク\\t大学\\t名詞-一般\\t\\t\\nで\\tデ\\tで\\t助詞-格助詞-一般\\t\\t\\n教育\\tキョウイク\\t教育\\t名詞-サ変接続\\t\\t\\nを\\tヲ\\tを\\t助詞-格助詞-一般\\t\\t\\n受ける\\tウケル\\t受ける\\t動詞-自立\\t一段\\t基本形\\nこと\\tコト\\tこと\\t名詞-非自立-一般\\t\\t\\nで\\tデ\\tで\\t助詞-格助詞-一般\\t\\t\\n就活\\t就活\\t就活\\t名詞-一般\\t\\t\\nにおいて\\tニオイテ\\tにおいて\\t助詞-格助詞-連語\\t\\t\\n有利\\tユウリ\\t有利\\t名詞-形容動詞語幹\\t\\t\\nに\\tニ\\tに\\t助詞-副詞化\\t\\t\\n働く\\tハタラク\\t働く\\t動詞-自立\\t五段・カ行イ音便\\t基本形\\nこと\\tコト\\tこと\\t名詞-非自立-一般\\t\\t\\nが\\tガ\\tが\\t助詞-格助詞-一般\\t\\t\\n周知\\tシュウチ\\t周知\\t名詞-サ変接続\\t\\t\\nの\\tノ\\tの\\t助詞-連体化\\t\\t\\n事実\\tジジツ\\t事実\\t名詞-副詞可能\\t\\t\\nです\\tデス\\tです\\t助動詞\\t特殊・デス\\t基本形\\nし\\tシ\\tし\\t助詞-接続助詞\\t\\t\\n，\\t，\\t，\\t記号-読点\\t\\t\\nその\\tソノ\\tその\\t連体詞\\t\\t\\n社会\\tシャカイ\\t社会\\t名詞-一般\\t\\t\\n人\\tジン\\t人\\t名詞-接尾-一般\\t\\t\\nに\\tニ\\tに\\t助詞-格助詞-一般\\t\\t\\nなる\\tナル\\tなる\\t動詞-自立\\t五段・ラ行\\t基本形\\n前\\tマエ\\t前\\t名詞-副詞可能\\t\\t\\nの\\tノ\\tの\\t助詞-連体化\\t\\t\\n準備\\tジュンビ\\t準備\\t名詞-サ変接続\\t\\t\\nが\\tガ\\tが\\t助詞-格助詞-一般\\t\\t\\nできる\\tデキル\\tできる\\t動詞-自立\\t一段\\t基本形\\nと\\tト\\tと\\t助詞-格助詞-引用\\t\\t\\n思い\\tオモイ\\t思う\\t動詞-自立\\t五段・ワ行促音便\\t連用形\\nます\\tマス\\tます\\t助動詞\\t特殊・マス\\t基本形\\n．\\t．\\t．\\t記号-句点\\t\\t\\nEOS\\n'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_mecab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "premier-ribbon",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-142-6572591d8409>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-142-6572591d8409>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    return word_list\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "for row in text_mecab[1].split(\"n\"):\n",
    "        word =row.split(\"t\")[0]#タブ区切りになっている１つ目を取り出す。ここには形態素が格納されている\n",
    "        if word == \"EOS\":\n",
    "            break\n",
    "        else:\n",
    "            pos = row.split(\"t\")[1]#タブ区切りになっている2つ目を取り出す。ここには品詞が格納されている\n",
    "            slice = pos[:2]\n",
    "            if slice == \"名詞\":\n",
    "                word_list = word_list +\" \"+ word\n",
    "        return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "micro-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "meisi = []\n",
    "for i in range(0, len(text)):\n",
    "    for line in tokenizer.parse(text[\"text\"][i]).splitlines():\n",
    "        if \"名詞\" in line.split()[-1]:\n",
    "            meisi.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eleven-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text)):\n",
    "    nouns = [line for line in tokenizer.parse(text[\"text\"][i]).splitlines()\n",
    "                   if \"名詞\" in line.split()[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "characteristic-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MeCab.Tagger(\"-Ochasen\")\n",
    "nouns = [line for line in tokenizer.parse(text[\"text\"][0]).splitlines()\n",
    "                   if \"副詞\" in line.split()[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "least-drunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['それだけ\\tソレダケ\\tそれだけ\\t副詞-助詞類接続\\t\\t',\n",
       " '結構\\tケッコウ\\t結構\\t副詞-一般\\t\\t',\n",
       " 'まあ\\tマア\\tまあ\\t副詞-一般\\t\\t',\n",
       " 'もっと\\tモット\\tもっと\\t副詞-一般\\t\\t']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "artificial-bicycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "delayed-battery",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f5576a28137e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmeisi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_mecab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     if \"名詞\" in line.split()[-1]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         meisi.append(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "meisi = []\n",
    "for i, line in range(0, len(text)):\n",
    "    for line in tokenizer.parse(text_mecab[i]).splitlines():\n",
    "    line = tokenizer.parse(text_mecab[i]).splitlines()\n",
    "#     if \"名詞\" in line.split()[-1]:\n",
    "#         meisi.append(a)\n",
    "# nouns = [line for line in m.parse(text).splitlines()\n",
    "#                if \"名詞\" in line.split()[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "discrete-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11876"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meisi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "planned-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "楽しい\t形容詞,自立,*,*,形容詞・イ段,基本形,楽しい,タノシイ,タノシイ\n",
      "な\t助詞,終助詞,*,*,*,*,な,ナ,ナ\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "tokenizer = MeCab.Tagger()\n",
    "print(tokenizer.parse('楽しいな'))\n",
    "a = tokenizer.parse('統計ラボはデータサイエンスとWebマーケティングをまとめたサイトです')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "split-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['，', '，', '，', '名詞-数']\n",
      "['大学', 'ダイガク', '大学', '名詞-一般']\n",
      "['自分', 'ジブン', '自分', '名詞-一般']\n",
      "['友人', 'ユウジン', '友人', '名詞-一般']\n",
      "['ん', 'ン', 'ん', '名詞-非自立-一般']\n",
      "['普通', 'フツウ', '普通', '名詞-形容動詞語幹']\n",
      "['就職', 'シュウショク', '就職', '名詞-サ変接続']\n",
      "['こと', 'コト', 'こと', '名詞-非自立-一般']\n",
      "['自分', 'ジブン', '自分', '名詞-一般']\n",
      "['こと', 'コト', 'こと', '名詞-非自立-一般']\n",
      "['大学', 'ダイガク', '大学', '名詞-一般']\n",
      "['こと', 'コト', 'こと', '名詞-非自立-一般']\n",
      "['会社', 'カイシャ', '会社', '名詞-一般']\n",
      "['の', 'ノ', 'の', '名詞-非自立-一般']\n",
      "['自分', 'ジブン', '自分', '名詞-一般']\n",
      "['こと', 'コト', 'こと', '名詞-非自立-一般']\n",
      "['大学', 'ダイガク', '大学', '名詞-一般']\n",
      "['ところ', 'トコロ', 'ところ', '名詞-非自立-副詞可能']\n",
      "['価値', 'カチ', '価値', '名詞-一般']\n"
     ]
    }
   ],
   "source": [
    "text = \"えーと，でもどりますと，大学に行っていない自分の友人がいるんですけど，それでも普通にえーと，えーと就職して働くことができていますし，自分のやりたいことはできていますし，大学に入ってまでえーと学ぶことでいけるえーと，会社っていうのもあると思うので，えーと自分がなりたいえーと，学びたいことをちゃんと大学で学べるかっていうところで価値があるかないかが決まってくると思います．\"\n",
    "m = MeCab.Tagger(\"-Ochasen\")\n",
    "\n",
    "\n",
    "nouns = [line for line in m.parse(text).splitlines()\n",
    "               if \"名詞\" in line.split()[-1]]\n",
    "nouns2 = [line for line in m.parse(text).splitlines()\n",
    "               if \"形容詞\" in line.split()[-1]]\n",
    "nouns3 = [line for line in m.parse(text).splitlines()\n",
    "               if \"副詞\" in line.split()[-1]]\n",
    "nouns4 = [line for line in m.parse(text).splitlines()\n",
    "               if \"助詞\" in line.split()[-1]]\n",
    "nouns5 = [line for line in m.parse(text).splitlines()\n",
    "               if \"フィラー\" in line.split()[-1]]\n",
    "\n",
    "for str in nouns:\n",
    "   print(str.split())\n",
    "   a = str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "equipped-acceptance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "0\n",
      "3\n",
      "36\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(nouns))\n",
    "print(len(nouns2))\n",
    "print(len(nouns3))\n",
    "print(len(nouns4))\n",
    "print(len(nouns5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regional-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    これは---D\n",
      "  カボチャの-D\n",
      "    テストです\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import CaboCha\n",
    "c = CaboCha.Parser()\n",
    "sentence = \"これはカボチャのテストです\"\n",
    "print(c.parseToString(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "banner-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import csv\n",
    " \n",
    "wordFreq_dic = {}\n",
    "wordcount_output = []\n",
    " \n",
    "#解析テキスト\n",
    "text = \"今日は楽しい。明日も楽しい。明後日は明日より楽しい。\"\n",
    " \n",
    "#単語頻出度カウント\n",
    "def WordFrequencyCount(word):\n",
    "        if word in wordFreq_dic:\n",
    "            wordFreq_dic[word] +=1\n",
    " \n",
    "        else:\n",
    "            wordFreq_dic.setdefault(word, 1)\n",
    "        return wordFreq_dic\n",
    " \n",
    "#特定の品詞の単語を抽出\n",
    "mecab = MeCab.Tagger()\n",
    "mecab.parse('')\n",
    "node = mecab.parseToNode(text)\n",
    " \n",
    "while node:\n",
    "    if node.feature.split(\",\")[0] == \"名詞\":\n",
    "        word = node.surface\n",
    "        WordFrequencyCount(word)\n",
    "    elif node.feature.split(\",\")[0] ==\"動詞\":\n",
    "        word = node.surface\n",
    "        WordFrequencyCount(word)\n",
    "    elif node.feature.split(\",\")[0] == \"形容詞\":\n",
    "        word = node.surface\n",
    "        WordFrequencyCount(word)\n",
    "    elif node.feature.split(\",\")[0] == \"形容動詞\":\n",
    "        word = node.surface\n",
    "        WordFrequencyCount(word)\n",
    "    else:pass\n",
    "    node = node.next\n",
    " \n",
    "#辞書リストを取り出し、降順に並び替え\n",
    "for item in wordFreq_dic.items():\n",
    "    wordcount_output.append(item)\n",
    "wordcount_output = sorted(wordcount_output, key = lambda x:x[1], reverse=True)\n",
    " \n",
    "#CSV出力\n",
    "with open(\"wordcount_dic.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f, lineterminator=\"\\n\")\n",
    "    writer.writerows(wordcount_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "million-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geturl(urls):\n",
    "    all_text=[]\n",
    "    for url in urls:\n",
    "        r=requests.get(url)\n",
    "        c=r.content\n",
    "        soup=BeautifulSoup(c,\"html.parser\")\n",
    "        article1_content=soup.find_all(\"p\")\n",
    "        temp=[]\n",
    "        for con in article1_content:\n",
    "            out=con.text\n",
    "            temp.append(out)\n",
    "        text=''.join(temp)\n",
    "        all_text.append(text)\n",
    "        sleep(1)\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "painted-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=MeCab.Tagger()\n",
    "m1=m.parse(\"統計ラボはデータサイエンスとWebマーケティングをまとめたサイトです\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "chemical-tennessee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'統計\\t名詞,サ変接続,*,*,*,*,統計,トウケイ,トーケイ\\nラボ\\t名詞,一般,*,*,*,*,ラボ,ラボ,ラボ\\nは\\t助詞,係助詞,*,*,*,*,は,ハ,ワ\\nデータ\\t名詞,一般,*,*,*,*,データ,データ,データ\\nサイエンス\\t名詞,一般,*,*,*,*,サイエンス,サイエンス,サイエンス\\nと\\t助詞,並立助詞,*,*,*,*,と,ト,ト\\nWeb\\t名詞,固有名詞,組織,*,*,*,*\\nマーケティング\\t名詞,一般,*,*,*,*,マーケティング,マーケティング,マーケティング\\nを\\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\\nまとめ\\t動詞,自立,*,*,一段,連用形,まとめる,マトメ,マトメ\\nた\\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\\nサイト\\t名詞,一般,*,*,*,*,サイト,サイト,サイト\\nです\\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\\nEOS\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "greatest-learning",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    return word_list\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "for row in m1.split(\"n\"):\n",
    "        word =row.split(\"t\")[0]#タブ区切りになっている１つ目を取り出す。ここには形態素が格納されている\n",
    "        if word == \"EOS\":\n",
    "            break\n",
    "        else:\n",
    "            pos = row.split(\"t\")[1]#タブ区切りになっている2つ目を取り出す。ここには品詞が格納されている\n",
    "            slice = pos[:2]\n",
    "            if slice == \"名詞\":\n",
    "                word_list = word_list +\" \"+ word\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "possible-carroll",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidURL",
     "evalue": "Failed to parse: 大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に価値があると思います．結構高校では教わらない専門的な知識も教えてもらえたりするし，まあ，もっと分野に対して詳しく説明されたりするから価値があると思います．",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocationParseError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLocationParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/util/url.py\u001b[0m in \u001b[0;36mparse_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocationParseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mLocationParseError\u001b[0m: Failed to parse: 大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に価値があると思います．結構高校では教わらない専門的な知識も教えてもらえたりするし，まあ，もっと分野に対して詳しく説明されたりするから価値があると思います．",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-f41d88de1928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m##実装\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeturl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mword_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmplg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-164-f41d88de1928>\u001b[0m in \u001b[0;36mgeturl\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mall_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msoup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         p.prepare(\n\u001b[0m\u001b[1;32m    457\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLocationParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidURL\u001b[0m: Failed to parse: 大学教育はそれだけの価値がありますかということで自分からはなさせて頂ますと，自分は大学教育に価値があると思います．結構高校では教わらない専門的な知識も教えてもらえたりするし，まあ，もっと分野に対して詳しく説明されたりするから価値があると思います．"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import MeCab\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "##関数定義\n",
    "# Step1：URLからテキスト情報をスクレイピング\n",
    "def geturl(urls):\n",
    "    all_text=[]\n",
    "    for url in urls:\n",
    "        r=requests.get(url)\n",
    "        c=r.content\n",
    "        soup=BeautifulSoup(c,\"html.parser\")\n",
    "        article1_content=soup.find_all(\"p\")\n",
    "        temp=[]\n",
    "        for con in article1_content:\n",
    "            out=con.text\n",
    "            temp.append(out)\n",
    "        text=''.join(temp)\n",
    "        all_text.append(text)\n",
    "        sleep(1)\n",
    "    return all_text\n",
    "\n",
    "# Step2：それらをMeCabで形態素解析。名詞だけ抽出。\n",
    "def mplg(article):\n",
    "    word_list = \"\"\n",
    "    m=MeCab.Tagger()\n",
    "    m1=m.parse (text)\n",
    "    for row in m1.split(\"\\n\"):\n",
    "        word =row.split(\"\\t\")[0]#タブ区切りになっている１つ目を取り出す。ここには形態素が格納されている\n",
    "        if word == \"EOS\":\n",
    "            break\n",
    "        else:\n",
    "            pos = row.split(\"\\t\")[1]#タブ区切りになっている2つ目を取り出す。ここには品詞が格納されている\n",
    "            slice = pos[:2]\n",
    "            if slice == \"名詞\":\n",
    "                word_list = word_list +\" \"+ word\n",
    "    return word_list\n",
    "\n",
    "# Step3：名詞の出現頻度からTF-IDF/COS類似度を算出。テキスト情報のマッチ度を測る\n",
    "def tfidf(word_list):\n",
    "    docs = np.array(word_list)#Numpyの配列に変換する\n",
    "    #単語を配列ベクトル化して、TF-IDFを計算する\n",
    "    vecs = TfidfVectorizer(\n",
    "                token_pattern=u'(?u)\\\\b\\\\w+\\\\b'#文字列長が 1 の単語を処理対象に含めることを意味します。\n",
    "                ).fit_transform(docs)\n",
    "    vecs = vecs.toarray()\n",
    "    return vecs\n",
    "\n",
    "\n",
    "def cossim(v1,v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "##実装\n",
    "word_list=[]\n",
    "texts=geturl([text[\"text\"][0]])\n",
    "for text in texts:\n",
    "    word_list.append(mplg(text))\n",
    "    \n",
    "vecs=tfidf(word_list)\n",
    "print(cossim(vecs[1],vecs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "equivalent-portrait",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-d75c83417bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "text[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-tuning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
